from config2 import *
import streamlit as st
import re
import os
import json
from datetime import datetime
from typing import TypedDict, List
from dotenv import load_dotenv
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain_community.vectorstores import Chroma
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import interrupt 
from langchain_core.tracers.context import tracing_v2_enabled

load_dotenv()

# LLM ë° ì„ë² ë”© ì´ˆê¸°í™”
embeddings = UpstageEmbeddings(model=EMBEDDING_MODEL)
llm = ChatUpstage(model=LLM_MODEL)

class ContractState(TypedDict):
    clause: str
    cleaned_text: str
    unfair_type: str
    related_cases: str
    improvement_proposal: str
    user_feedback: str
    modify_reason: str
    retry_action: str
    session_id: str
    iteration: int
    validation_failed: bool
    retrieved_cases_metadata: List[dict]
    retrieved_laws_metadata: List[dict]
    similarity_threshold: float

def load_vectordb():
    print("ë²¡í„° DB ë¡œë“œ ì¤‘...")
    vectorstore = Chroma(
        embedding_function=embeddings,
        persist_directory="./chroma_db",
        collection_name="contract_laws",
        collection_metadata={"hnsw:space": "cosine"}
    )
    print("ë²¡í„° DB ë¡œë“œ ì™„ë£Œ!\n")
    return vectorstore

def is_valid_contract_clause(clause: str) -> tuple[bool, str]:
    clause = clause.strip()
    
    if len(clause) < 20:
        return False, "ì…ë ¥ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (ìµœì†Œ 20ì í•„ìš”)"
    
    contract_keywords = [
        'ì¡°í•­', 'ì¡°ê±´', 'ì•½ê´€', 'ê·œì •', 'ì œ', 'í•­', 'ì¡°', 'ì',
        'ê¸ˆì§€', 'ê°€ëŠ¥', 'ë¶ˆê°€', 'ì˜ë¬´', 'ì±…ì„', 'ê¶Œë¦¬', 'ê³„ì•½',
        'í•´ì§€', 'ì¤‘ë‹¨', 'ë³€ê²½', 'í™˜ë¶ˆ', 'ë°°ìƒ', 'ë°°ì œ', 'ë©´ì±…',
        'ìˆ˜ìˆ˜ë£Œ', 'ì´ìš©ë£Œ', 'ê²°ì œ', 'í• ì¸', 'ì„œë¹„ìŠ¤', 'ì œê³µ',
        'ê°œì¸ì •ë³´', 'ë³´í˜¸', 'ì´ìš©', 'ê´€ë¦¬', 'í†µì§€', 'ë™ì˜',
        'ìœ íš¨', 'ê¸°ê°„', 'ìƒí˜¸', 'ì‹œí–‰', 'íš¨ë ¥', 'ì²­êµ¬', 'ìœ„ë°˜',
        'ì†í•´ë°°ìƒ', 'ë©´ì±…ì¡°í•­', 'ì´ìš©ì', 'íšŒì‚¬', 'ë‹¹ì‚¬ì'
    ]
    
    has_keyword = any(keyword in clause for keyword in contract_keywords)
    
    if not has_keyword:
        return False, "ì•½ê´€ ê´€ë ¨ í‚¤ì›Œë“œ ë¯¸ê²€ì¶œ (ì˜ˆ: ì¡°í•­, ì•½ê´€, ì¡°ê±´, ì˜ë¬´ ë“±)"
    
    question_marks = ['?', '?']
    is_question = any(q in clause for q in question_marks)
    
    if is_question:
        return False, "ì§ˆë¬¸ í˜•ì‹ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì•½ê´€ ì¡°í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”"
    
    return True, "ê²€ì¦ í†µê³¼"

def clean_text_node(state: ContractState):
    print(f"\n[ë…¸ë“œ1] Rule-based ê²€ì¦ + í…ìŠ¤íŠ¸ ì •ì œ\n")
    
    is_valid, validation_msg = is_valid_contract_clause(state['clause'])
    print(f"[Rule-based ê²€ì¦ ê²°ê³¼] {validation_msg}")
    
    if not is_valid:
        print(f"-> API í˜¸ì¶œ ì¤‘ë‹¨\n")
        return {
            "cleaned_text": "[ë£° ë² ì´ìŠ¤ ê±°ë¶€] ì•½ê´€ ì¡°í•­ì´ ì•„ë‹˜",
            "validation_failed": True
        }
    
    print(f"-> ê²€ì¦ í†µê³¼\n")
    
    original_text = state['clause']
    cleaned = original_text
    
    cleaned = re.sub(r'^[\sâ€¢\-\*]+', '', cleaned, flags=re.MULTILINE)
    cleaned = re.sub(r'[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\s*', '', cleaned)
    cleaned = re.sub(r'\(\d+\)\s*', '', cleaned)
    cleaned = re.sub(r'\s+', ' ', cleaned)
    cleaned = cleaned.strip()
    
    print(f"[ì •ì œ ì „] {len(original_text)}ì")
    print(f"{original_text}\n")
    print(f"[ì •ì œ í›„] {len(cleaned)}ì")
    print(f"{cleaned}\n")
    
    return {
        "cleaned_text": cleaned,
        "validation_failed": False
    }

def classify_type_node(state: ContractState):
    print(f"[ë…¸ë“œ2] Solar API - ë¶ˆê³µì • ìœ í˜• ë¶„ë¥˜\n")
    
    prompt = f"""ë‹¤ìŒ ì•½ê´€ ì¡°í•­ì˜ ë¶ˆê³µì • ìœ í˜•ì„ íŒë‹¨í•˜ì„¸ìš”:

{state['cleaned_text']}

ìœ í˜•:
1. ì„œë¹„ìŠ¤ ì¼ë°©ì  ë³€ê²½Â·ì¤‘ë‹¨
2. ê¸°í•œì˜ ì´ìµ ìƒì‹¤
3. ê³ ê° ê¶Œë¦¬ ì œí•œ
4. í†µì§€Â·ê³ ì§€ ë¶€ì ì ˆ
5. ê³„ì•½ í•´ì§€Â·ë³€ê²½ ì‚¬ìœ  í¬ê´„ì 
6. ë¹„ìš© ê³¼ë‹¤ ë¶€ê³¼Â·í™˜ê¸‰ ì œí•œ
7. ë©´ì±…Â·ì±…ì„ ì „ê°€
8. ê¸°íƒ€ ë¶ˆê³µì • ì•½ê´€
ìœ„ 7ê°€ì§€ ìœ í˜•ì— í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´ "8. ê¸°íƒ€ ë¶ˆê³µì • ì•½ê´€"ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.

í•´ë‹¹ ìœ í˜•ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
    
    unfair_type = llm.invoke(prompt).content.strip()
    
    print(f"ë¶„ë¥˜ ê²°ê³¼: {unfair_type}\n")
    
    return {"unfair_type": unfair_type}

def retrieve_node(state: ContractState, vectorstore):
    
    current_threshold = state.get('similarity_threshold', SIMILARITY_THRESHOLD)
    print(f"[ë…¸ë“œ3] ê²€ìƒ‰ (ì„ê³„ê°’: {current_threshold:.0%})")
    
    search_query = f"{state['unfair_type']} {state['cleaned_text']}"
    
    # 1. ì‚¬ë¡€ ê²€ìƒ‰ (ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨)
    # ì´ í•¨ìˆ˜ëŠ” (doc, similarity_score) íŠœí”Œì„ ë°˜í™˜í•©ë‹ˆë‹¤. (1.0ì´ 100% ìœ ì‚¬)
    results_cases_with_scores = vectorstore.similarity_search_with_relevance_scores(
        search_query, 
        k=SEARCH_TOP_K_CASES, 
        filter={"source_type": "case"}
    )
    
    filtered_cases_meta = []
    
    for i, (doc, similarity_score) in enumerate(results_cases_with_scores, 1):
        
        # similarity_score (ì˜ˆ: 0.75)ë¥¼ current_threshold (ì˜ˆ: 0.70)ì™€ ì§ì ‘ ë¹„êµ
        if similarity_score >= current_threshold:
            print(f"  âœ“ ì‚¬ë¡€ í†µê³¼ (ìœ ì‚¬ë„ {similarity_score:.1%})") # ë””ë²„ê¹…ìš© ë¡œê·¸
            filtered_cases_meta.append({
                "index": i,
                "similarity": similarity_score, # ê³„ì‚°ì´ ì•„ë‹Œ, ë°˜í™˜ëœ ì ìˆ˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                "content": doc.page_content,
                "date": doc.metadata.get('date', 'N/A'),
                "case_type": doc.metadata.get('case_type', ''),
                "explanation": doc.metadata.get('explanation', ''),
                "conclusion": doc.metadata.get('conclusion', ''),
                "related_law": doc.metadata.get('related_law', '')
            })
        else:
             print(f"  âœ— ì‚¬ë¡€ í•„í„°ë¨ (ìœ ì‚¬ë„ {similarity_score:.1%})") # ë””ë²„ê¹…ìš© ë¡œê·¸

    # í‘œì‹œ ê°œìˆ˜ ì œí•œ
    final_cases_meta = filtered_cases_meta[:MAX_DISPLAY_CASES]
    
    # 2. ë²•ë ¹ ê²€ìƒ‰
    law_query = " ".join([c['related_law'] for c in final_cases_meta if c['related_law']])
    if not law_query: law_query = search_query
        
    results_laws_with_scores = vectorstore.similarity_search_with_relevance_scores(
        law_query, 
        k=SEARCH_TOP_K_LAWS, 
        filter={"source_type": "law"}
    )
    
    final_laws_meta = []
    for i, (doc, similarity_score) in enumerate(results_laws_with_scores, 1):
        if similarity_score >= current_threshold:
            final_laws_meta.append({
                "index": i,
                "similarity": similarity_score,
                "content": doc.page_content
            })
    final_laws_meta = final_laws_meta[:MAX_DISPLAY_LAWS]

    # 3. LLM í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ ìƒì„±
    retrieved_text = f"[ìœ ì‚¬ ì‹œì • ì‚¬ë¡€] ({len(final_cases_meta)}ê±´, ì„ê³„ì : {current_threshold:.0%})\n"
    
    for c in final_cases_meta:
        retrieved_text += f"\n- ì‚¬ë¡€{c['index']} (ìœ ì‚¬ë„ {c['similarity']:.1%}): {c['content']}\n"
        if c['related_law']:
            retrieved_text += f"  (ê´€ë ¨ë²•: {c['related_law']})\n"
    
    retrieved_text += f"\n[ê´€ë ¨ ë²•ë ¹] ({len(final_laws_meta)}ê±´)\n"
    for l in final_laws_meta:
        retrieved_text += f"- ë²•ë ¹{l['index']} (ìœ ì‚¬ë„ {l['similarity']:.1%}): {l['content']}\n"

    return {
        "related_cases": retrieved_text,
        "retrieved_cases_metadata": final_cases_meta,
        "retrieved_laws_metadata": final_laws_meta
    }

def generate_proposal_node(state: ContractState):
    print(f"[ë…¸ë“œ4] Solar API - ê°œì„ ì•ˆ ìƒì„± (ë°˜ë³µ: {state['iteration']}/{MAX_ITERATIONS})\n")
    
    feedback_context = ""
    if state.get('modify_reason'):
        feedback_context = f"\n[ì‚¬ìš©ì í”¼ë“œë°±]\n{state['modify_reason']}\nìœ„ ì˜ê²¬ì„ ë°˜ì˜í•´ ë‹¤ì‹œ ì‘ì„±í•˜ì„¸ìš”.\n"
    
    prompt = f"""ë‹¹ì‹ ì€ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ì›ë³¸ ì•½ê´€ ì¡°í•­]
{state['cleaned_text']}

[ë¶ˆê³µì • ìœ í˜•]
{state['unfair_type']}

[ê´€ë ¨ ì‹œì • ì‚¬ë¡€ ë° ë²•ë ¹]
{state['related_cases']}

{feedback_context}

[ì‘ì—…]
ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ ì•½ê´€ ì¡°í•­ì„ ê³µì •í•œ ì•½ê´€ìœ¼ë¡œ ê°œì„ í•˜ì„¸ìš”.

[ì¤‘ìš” ê·œì¹™]
- ë²• ê·¼ê±°ëŠ” ìœ„ì˜ "ê´€ë ¨ ì‹œì • ì‚¬ë¡€ ë° ë²•ë ¹"ì— ëª…ì‹œëœ ê²ƒë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
- ê·¼ê±° ì—†ëŠ” ë²•ë ¹ì´ë‚˜ ì¡°í•­, íŠ¹ì • ê¸°ê°„(6ê°œì›”, 90ì¼ ë“±)ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- ê´€ë ¨ ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.

[ì¶œë ¥ í˜•ì‹]
1. ê°œì„ ëœ ì•½ê´€ ì¡°í•­
2. ê°œì„  ì‚¬ìœ  (ê´€ë ¨ ì‹œì • ì‚¬ë¡€ ë° ë²•ë ¹ì—ì„œë§Œ ì œì‹œ)
3. í•µì‹¬ ë³€ê²½ ì‚¬í•­"""
    
    proposal = llm.invoke(prompt).content
    
    print(f"ê°œì„ ì•ˆ ìƒì„± ì™„ë£Œ (ë°˜ë³µ: {state['iteration']}/{MAX_ITERATIONS})\n")
    
    return {"improvement_proposal": proposal}

def ui_feedback_node(state: ContractState):
    print(f"\n[ë…¸ë“œ5] UI í”¼ë“œë°± ëŒ€ê¸° (ë°˜ë³µ: {state['iteration']}/{MAX_ITERATIONS})\n")
    print(f"ê°œì„ ì•ˆ:\n{state['improvement_proposal']}\n")
    
    if state.get('retrieved_cases_metadata'):
        print(f"ì°¸ê³ í•œ ì‚¬ë¡€ ìˆ˜: {len(state['retrieved_cases_metadata'])}ê°œ")
        for case in state['retrieved_cases_metadata']:
            print(f"  - ì‚¬ë¡€ {case['index']}: ìœ ì‚¬ë„ {case['similarity']:.2%}")
    
    return interrupt(state)

def process_feedback_node(state: ContractState):
    feedback = state['user_feedback']
    retry_action = state.get('retry_action', '')
    current_iteration = state.get('iteration', 1)
    
    if feedback == "approved":
        save_result(
            state=state,
            status="approved",
            iteration=current_iteration,
            total_iterations=current_iteration
        )
        print("[ë…¸ë“œ6] ê²°ê³¼ ì €ì¥ ì™„ë£Œ (ìˆ˜ë½)")
        print(f"ì´ {current_iteration}íšŒ ë°˜ë³µ í›„ ì™„ë£Œ\n")
        return {
            "user_feedback": "approved",
            "retry_action": ""
        }
    
    elif feedback == "rejected":
        if retry_action == "retry":
            new_iteration = current_iteration + 1
            save_result(
                state=state,
                status="rejected_retry",
                iteration=current_iteration
            )
            print(f"[ë…¸ë“œ6] ê±°ì ˆ ê¸°ë¡ (ì¬ì‹œë„ ì˜ˆì •)")
            print(f"-> ë°˜ë³µ {new_iteration}ì°¨ ì§„í–‰\n")
            return {
                "user_feedback": "rejected",
                "iteration": new_iteration,
                "retry_action": "retry"
            }
        else:
            save_result(
                state=state,
                status="rejected_discard",
                iteration=current_iteration,
                total_iterations=current_iteration
            )
            print(f"[ë…¸ë“œ6] ê²°ê³¼ ì €ì¥ ì™„ë£Œ (ê±°ì ˆ ë° íê¸°)\n")
            return {
                "user_feedback": "rejected",
                "retry_action": "discard"
            }
    
    elif feedback == "modify":
        if current_iteration >= MAX_ITERATIONS:
            save_result(
                state=state,
                status="max_iteration_reached",
                iteration=current_iteration,
                total_iterations=current_iteration,
                modify_reason="ë°˜ë³µ íšŸìˆ˜ ì œí•œ ë„ë‹¬"
            )
            print(f"[ë…¸ë“œ6] ë°˜ë³µ íšŸìˆ˜ ì œí•œ ë„ë‹¬")
            print(f"ì´ {current_iteration}íšŒ ë°˜ë³µ (ìµœëŒ€ê°’)\n")
            return {
                "user_feedback": "approved", 
                "retry_action": ""
            }
        
        new_iteration = current_iteration + 1
        save_result(
            state=state,
            status="modify_request",
            iteration=current_iteration,
            modify_reason=state.get('modify_reason', '')
        )
        print(f"[ë…¸ë“œ6] ìˆ˜ì • ìš”ì²­ ì €ì¥")
        print(f"-> ë°˜ë³µ {new_iteration}ì°¨ ì§„í–‰\n")
        return {
            "user_feedback": "modify",
            "iteration": new_iteration,
            "modify_reason": state.get('modify_reason', ''),
            "retry_action": ""
        }
    
    return {
        "user_feedback": feedback,
        "retry_action": ""
    }

def route_feedback(state: ContractState) -> str:
    if state.get('validation_failed', False):
        print("\n[ë¼ìš°íŒ… ê·œì¹™ ì ìš©]")
        print(f"- ì¡°ê±´: validation_failed == True")
        print(f"- ì•¡ì…˜: ê·¸ë˜í”„ ì¦‰ì‹œ ì¢…ë£Œ")
        print(f"- ìƒíƒœ: ë£°ë² ì´ìŠ¤ ê²€ì¦ ì‹¤íŒ¨\n")
        return "end"
    
    feedback = state.get('user_feedback', '').lower()
    retry_action = state.get('retry_action', '')
    current_iteration = state.get('iteration', 1)
    
    print(f"\n[ë¼ìš°íŒ… ê·œì¹™ ì ìš© - ë°˜ë³µ íšŸìˆ˜: {current_iteration}/{MAX_ITERATIONS}]")
    
    if feedback == "approved":
        print(f"- ì¡°ê±´: user_feedback == 'approved'")
        print(f"- ì•¡ì…˜: ê·¸ë˜í”„ ì¢…ë£Œ (ê²°ê³¼ ì €ì¥)")
        print(f"- ìƒíƒœ: ì™„ë£Œ\n")
        return "end"
    
    elif feedback == "rejected" and retry_action == "retry":
        print(f"- ì¡°ê±´: user_feedback == 'rejected' AND retry_action == 'retry'")
        print(f"- ì•¡ì…˜: generate ë…¸ë“œë¡œ ì´ë™ (ë‹¤ë¥¸ ê°œì„ ì•ˆ ìƒì„±)")
        print(f"- ìƒíƒœ: ì¬ì‹œë„ (ìƒˆë¡œìš´ ê°œì„ ì•ˆ)\n")
        return "generate"
    
    elif feedback == "rejected" and retry_action == "discard":
        print(f"- ì¡°ê±´: user_feedback == 'rejected' AND retry_action == 'discard'")
        print(f"- ì•¡ì…˜: ê·¸ë˜í”„ ì¢…ë£Œ (íê¸°)")
        print(f"- ìƒíƒœ: ê±°ì ˆ ë° íê¸°\n")
        return "end"
    
    elif feedback == "modify" and current_iteration < MAX_ITERATIONS:
        next_iteration = current_iteration + 1
        print(f"- ì¡°ê±´: user_feedback == 'modify' AND iteration({current_iteration}) < MAX({MAX_ITERATIONS})")
        print(f"- ì•¡ì…˜: generate ë…¸ë“œë¡œ ì´ë™ (í”¼ë“œë°± ë°˜ì˜)")
        print(f"- ìƒíƒœ: ë°˜ë³µ {next_iteration}ì°¨ ì§„í–‰\n")
        return "generate"
    
    elif feedback == "modify" and current_iteration >= MAX_ITERATIONS:
        print(f"- ì¡°ê±´: user_feedback == 'modify' AND iteration({current_iteration}) >= MAX({MAX_ITERATIONS})")
        print(f"- ë°˜ë³µ íšŸìˆ˜ ì œí•œ ë„ë‹¬!")
        print(f"- ì•¡ì…˜: ê·¸ë˜í”„ ì¢…ë£Œ (ê°•ì œ)")
        print(f"- ìƒíƒœ: ë°˜ë³µ ì œí•œ ë„ë‹¬\n")
        return "end"
    
    else:
        print(f"- ê¸°íƒ€ ì¡°ê±´")
        print(f"- ì•¡ì…˜: ê·¸ë˜í”„ ì¢…ë£Œ\n")
        return "end"

def save_result(state: ContractState, status: str, iteration: int,
                modify_reason: str = "", total_iterations: int = None):
    result = {
        "timestamp": datetime.now().isoformat(),
        "session_id": state['session_id'],
        "status": status,
        "iteration": iteration,
        "total_iterations": total_iterations or iteration,
        "original_clause": state['clause'],
        "cleaned_text": state['cleaned_text'],
        "unfair_type": state['unfair_type'],
        "improvement_proposal": state['improvement_proposal'],
        "modify_reason": modify_reason
    }
    
    filename = f"{status}_data.jsonl"
    with open(filename, 'a', encoding='utf-8') as f:
        f.write(json.dumps(result, ensure_ascii=False) + '\n')

@st.cache_resource
def get_app_and_vectorstore():
    vectorstore = load_vectordb()
    
    graph = StateGraph(ContractState)
    
    graph.add_node("clean", clean_text_node)
    graph.add_node("classify", classify_type_node)
    graph.add_node("retrieve", lambda state: retrieve_node(state, vectorstore))
    graph.add_node("generate", generate_proposal_node)
    graph.add_node("feedback", ui_feedback_node)
    graph.add_node("process_feedback", process_feedback_node)
    
    graph.set_entry_point("clean")
    
    def route_after_clean(state: ContractState) -> str:
        if state.get('validation_failed', False):
            return "end"
        return "classify"
    
    graph.add_conditional_edges(
        "clean",
        route_after_clean,
        {
            "end": END,
            "classify": "classify"
        }
    )
    
    graph.add_edge("classify", "retrieve")
    graph.add_edge("retrieve", "generate")
    graph.add_edge("generate", "feedback")
    graph.add_edge("feedback", "process_feedback")
    
    graph.add_conditional_edges(
        "process_feedback",
        route_feedback,
        {
            "end": END,
            "generate": "generate"
        }
    )
    
    checkpointer = MemorySaver()
    app = graph.compile(checkpointer=checkpointer)
    
    return app

def main_chatbot_ui():
    st.set_page_config(page_title="ë²•ë¥  ì•½ê´€ ê²€í†  ì±—ë´‡", layout="wide")
    st.title("ë²•ë¥  ì•½ê´€ ê²€í†  ì±—ë´‡")
    
    with st.sidebar:
        st.header("ê²€ìƒ‰ ì„¤ì •")
        similarity_threshold_percent = st.slider(
            "ìœ ì‚¬ë„ ì„ê³„ê°’ (%)",
            min_value=0,
            max_value=100,
            value=int(SIMILARITY_THRESHOLD * 100), # config ê¸°ë³¸ê°’ ì‚¬ìš©
            step=5,
            format="%d%%"
        )
        current_threshold_value = similarity_threshold_percent / 100.0
        st.caption(f"í˜„ì¬ ì„¤ì •: {similarity_threshold_percent}% ì´ìƒ")
        st.divider()

    try:
        app = get_app_and_vectorstore()
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.error("Chroma DB íŒŒì¼('./chroma_db')ì´ ì˜¬ë°”ë¥´ê²Œ ìœ„ì¹˜í•´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "thread_id" not in st.session_state:
        st.session_state.thread_id = None
    if "hitl_pending" not in st.session_state:
        st.session_state.hitl_pending = False
    if "current_state" not in st.session_state:
        st.session_state.current_state = {}
    if "pending_feedback" not in st.session_state:
        st.session_state.pending_feedback = None

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if st.session_state.hitl_pending:
        current_iteration = st.session_state.current_state.get('iteration', 1)
        used_threshold = st.session_state.current_state.get('similarity_threshold', SIMILARITY_THRESHOLD)
        st.info(f"ê°œì„ ì•ˆ (ë°˜ë³µ {current_iteration}/{MAX_ITERATIONS})ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì£¼ì„¸ìš”.")

        if SHOW_RETRIEVED_CASES:
            with st.expander("ì°¸ê³ í•œ ìœ ì‚¬ ì‚¬ë¡€ ë³´ê¸°", expanded=True):
                cases = st.session_state.current_state.get('retrieved_cases_metadata', [])
                
                if cases:
                    st.caption(f"ì´ {len(cases)}ê°œ ì‚¬ë¡€ (ìœ ì‚¬ë„ {used_threshold:.0%} ì´ìƒ)")
                    
                    for case in cases:
                        similarity = case['similarity']
                        
                        if similarity >= 0.7:
                            color = "ğŸŸ¢"
                        elif similarity >= 0.5:
                            color = "ğŸŸ¡"
                        else:
                            color = "ğŸŸ "
                        
                        st.markdown(f"### {color} ì‚¬ë¡€ {case['index']} - ìœ ì‚¬ë„: {similarity:.1%}")
                        st.caption(f"ğŸ“… {case['date']} | ìœ í˜•: {case['case_type']}")
                        
                        with st.container():
                            st.markdown("**ì•½ê´€ ì¡°í•­:**")
                            st.info(case['content'].split('ê²°ë¡ :')[0].replace('ì•½ê´€: ', '').strip())
                            
                            if case['explanation']:
                                st.markdown("**ì‹œì • ìš”ì²­ ì‚¬ìœ :**")
                                st.warning(case['explanation'])
                            
                            if case['conclusion']:
                                st.markdown("**ìµœì¢… ê²°ë¡ :**")
                                st.success(case['conclusion'])
                            
                            if case['related_law']:
                                st.caption(f"ğŸ”— ê´€ë ¨ë²•: {case['related_law']}")
                        
                        st.divider()
                else:
                    st.warning("ê²€ìƒ‰ëœ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤.")

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ìˆ˜ì • ìš”ì²­ (Modify)")
            modify_reason = st.text_area("ìˆ˜ì • ìš”ì²­ ì‚¬ìœ :", key="modify_reason_input")
            
            if current_iteration >= MAX_ITERATIONS:
                st.warning(f"ë°˜ë³µ íšŸìˆ˜ ì œí•œ({MAX_ITERATIONS}íšŒ)ì— ë„ë‹¬í•˜ì—¬ ë” ì´ìƒ ìˆ˜ì • ìš”ì²­ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                if st.button("í˜„ì¬ ê°œì„ ì•ˆ ìˆ˜ë½ (Approve)", use_container_width=True, type="primary"):
                    st.session_state.pending_feedback = {
                        "user_feedback": "approved",
                        "modify_reason": "ë°˜ë³µ íšŸìˆ˜ ì œí•œ ë„ë‹¬",
                        "retry_action": ""
                    }
                    st.session_state.hitl_pending = False
                    st.session_state.messages.append({
                        "role": "user", 
                        "content": "[í”¼ë“œë°±] ë°˜ë³µ ì´ˆê³¼ë¡œ í˜„ì¬ ê°œì„ ì•ˆì„ ìˆ˜ë½í•©ë‹ˆë‹¤."
                    })
                    st.rerun()
            else:
                if st.button("ìˆ˜ì • ìš”ì²­ ì œì¶œ (Modify)", key="modify_btn", use_container_width=True):
                    if not modify_reason.strip():
                        st.error("ìˆ˜ì • ìš”ì²­ ì‚¬ìœ ë¥¼ ë°˜ë“œì‹œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
                    else:
                        st.session_state.pending_feedback = {
                            "user_feedback": "modify",
                            "modify_reason": modify_reason.strip(),
                            "retry_action": ""
                        }
                        st.session_state.hitl_pending = False
                        st.session_state.messages.append({
                            "role": "user", 
                            "content": f"[í”¼ë“œë°±] ìˆ˜ì • ìš”ì²­:\n{modify_reason.strip()}"
                        })
                        st.rerun()

        with col2:
            st.subheader("ìˆ˜ë½ ë˜ëŠ” ê±°ì ˆ (Approve / Reject)")
            if st.button("ê°œì„ ì•ˆ ìˆ˜ë½ (Approve)", key="approve_btn", use_container_width=True):
                st.session_state.pending_feedback = {
                    "user_feedback": "approved",
                    "modify_reason": "",
                    "retry_action": ""
                }
                st.session_state.hitl_pending = False
                st.session_state.messages.append({
                    "role": "user", 
                    "content": "[í”¼ë“œë°±] ê°œì„ ì•ˆì„ ìˆ˜ë½í•©ë‹ˆë‹¤ (ì™„ë£Œ)."
                })
                st.rerun()

            if st.button("ë‹¤ë¥¸ ê°œì„ ì•ˆ ìƒì„± (Reject + Retry)", key="retry_btn", use_container_width=True):
                st.session_state.pending_feedback = {
                    "user_feedback": "rejected",
                    "retry_action": "retry",
                    "modify_reason": ""
                }
                st.session_state.hitl_pending = False
                st.session_state.messages.append({
                    "role": "user", 
                    "content": "[í”¼ë“œë°±] ê±°ì ˆ (ë‹¤ë¥¸ ê°œì„ ì•ˆ ì¬ì‹œë„)."
                })
                st.rerun()

            if st.button("íê¸° (Reject + Discard)", key="discard_btn", use_container_width=True):
                st.session_state.pending_feedback = {
                    "user_feedback": "rejected",
                    "retry_action": "discard",
                    "modify_reason": ""
                }
                st.session_state.hitl_pending = False
                st.session_state.messages.append({
                    "role": "user", 
                    "content": "[í”¼ë“œë°±] ê±°ì ˆ (ê²€í†  íê¸°)."
                })
                st.rerun()
        
        st.chat_input("í”¼ë“œë°±ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.", disabled=True)

    else:
        if st.session_state.pending_feedback is not None:
            feedback_input = st.session_state.pending_feedback
            st.session_state.pending_feedback = None
            
            config = {"configurable": {"thread_id": st.session_state.thread_id}}
            
            with st.chat_message("assistant"):
                with st.spinner("í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ì²˜ë¦¬ ì¤‘..."):
                    try:
                        output = app.invoke(feedback_input, config=config)
                        st.session_state.current_state = output
                        
                        last_feedback = output.get('user_feedback', '')
                        last_retry = output.get('retry_action', '')

                        if last_feedback == "approved" or (last_feedback == "rejected" and last_retry == "discard"):
                            st.markdown("### ê²€í†  ì™„ë£Œ\nê²€í† ê°€ ìµœì¢… ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": "ê²€í† ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
                            })
                            st.rerun()
                        else:
                            st.markdown(f"### ğŸ”„ ìƒˆë¡œìš´ ê°œì„ ì•ˆ (ë°˜ë³µ {output.get('iteration', '?')}/{MAX_ITERATIONS})")
                            st.markdown(output['improvement_proposal'])
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": output['improvement_proposal']
                            })
                            st.session_state.hitl_pending = True
                            st.rerun()

                    except Exception as e:
                        st.error(f"í”¼ë“œë°± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        st.session_state.hitl_pending = False
                        st.session_state.thread_id = None
                        st.session_state.current_state = {}

        elif prompt := st.chat_input("ê²€í† í•  ì•½ê´€ ì¡°í•­ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                with st.spinner("ì•½ê´€ ì¡°í•­ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        st.session_state.thread_id = f"session_{datetime.now().timestamp()}"
                        config = {"configurable": {"thread_id": st.session_state.thread_id}}
                        
                        initial_state = {
                            "clause": prompt,
                            "iteration": 1,
                            "session_id": st.session_state.thread_id,
                            "validation_failed": False,
                            "retrieved_cases_metadata": [],
                            "retrieved_laws_metadata": [],
                            "similarity_threshold": current_threshold_value
                        }
                        
                        with tracing_v2_enabled():
                            output = app.invoke(initial_state, config=config)
                        
                        st.session_state.current_state = output
                        
                        if output.get('validation_failed', False):
                            error_msg = f"ì…ë ¥ ì˜¤ë¥˜: {output.get('cleaned_text', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                            st.error(error_msg)
                            st.session_state.messages.append({"role": "assistant", "content": error_msg})
                            st.session_state.thread_id = None
                        else:
                            st.markdown("### ì œì•ˆ (ì²« ë²ˆì§¸ ê°œì„ ì•ˆ)")
                            st.markdown(output['improvement_proposal'])
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": output['improvement_proposal']
                            })
                            st.session_state.hitl_pending = True
                            st.rerun()

                    except Exception as e:
                        st.error(f"ì•½ê´€ ê²€í†  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        import traceback
                        st.exception(traceback.format_exc())
                        st.session_state.thread_id = None
                        st.session_state.hitl_pending = False
                        st.session_state.current_state = {}


if __name__ == "__main__":
    main_chatbot_ui()