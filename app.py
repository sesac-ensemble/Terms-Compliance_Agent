from config2 import *
import streamlit as st
import re
import os
import json
from datetime import datetime
from typing import TypedDict, List
from dotenv import load_dotenv
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain_community.vectorstores import Chroma
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import interrupt 
from langchain_core.tracers.context import tracing_v2_enabled
import pypdf
from langchain.text_splitter import RecursiveCharacterTextSplitter
from prompts_app import ACTIVE_UNFAIR_TYPE_PROMPT, ACTIVE_IMPROVEMENT_PROMPT

load_dotenv()

# LLM ë° ì„ë² ë”© ì´ˆê¸°í™”
embeddings = UpstageEmbeddings(model=EMBEDDING_MODEL)
llm = ChatUpstage(model=LLM_MODEL)

class ContractState(TypedDict):
    clause: str
    cleaned_text: str
    unfair_type: str
    related_cases: str
    improvement_proposal: str
    user_feedback: str
    modify_reason: str
    retry_action: str
    session_id: str
    iteration: int
    validation_failed: bool
    retrieved_cases_metadata: List[dict]
    retrieved_laws_metadata: List[dict]
    similarity_threshold: float

def load_vectordb():
    print("ë²¡í„° DB ë¡œë“œ ì¤‘...")
    vectorstore = Chroma(
        embedding_function=embeddings,
        persist_directory="./chroma_db",
        collection_name="contract_laws",
        collection_metadata={"hnsw:space": "cosine"}
    )
    print("ë²¡í„° DB ë¡œë“œ ì™„ë£Œ!\n")
    return vectorstore

def is_valid_contract_clause(clause: str) -> tuple[bool, str]:
    clause = clause.strip()
    
    if len(clause) < 20:
        return False, "ì…ë ¥ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (ìµœì†Œ 20ì í•„ìš”)"
    
    contract_keywords = [
        'ì¡°í•­', 'ì¡°ê±´', 'ì•½ê´€', 'ê·œì •', 'ì œ', 'í•­', 'ì¡°', 'ì',
        'ê¸ˆì§€', 'ê°€ëŠ¥', 'ë¶ˆê°€', 'ì˜ë¬´', 'ì±…ì„', 'ê¶Œë¦¬', 'ê³„ì•½',
        'í•´ì§€', 'ì¤‘ë‹¨', 'ë³€ê²½', 'í™˜ë¶ˆ', 'ë°°ìƒ', 'ë°°ì œ', 'ë©´ì±…',
        'ìˆ˜ìˆ˜ë£Œ', 'ì´ìš©ë£Œ', 'ê²°ì œ', 'í• ì¸', 'ì„œë¹„ìŠ¤', 'ì œê³µ',
        'ê°œì¸ì •ë³´', 'ë³´í˜¸', 'ì´ìš©', 'ê´€ë¦¬', 'í†µì§€', 'ë™ì˜',
        'ìœ íš¨', 'ê¸°ê°„', 'ìƒí˜¸', 'ì‹œí–‰', 'íš¨ë ¥', 'ì²­êµ¬', 'ìœ„ë°˜',
        'ì†í•´ë°°ìƒ', 'ë©´ì±…ì¡°í•­', 'ì´ìš©ì', 'íšŒì‚¬', 'ë‹¹ì‚¬ì'
    ]
    
    has_keyword = any(keyword in clause for keyword in contract_keywords)
    
    if not has_keyword:
        return False, "ì•½ê´€ ê´€ë ¨ í‚¤ì›Œë“œ ë¯¸ê²€ì¶œ (ì˜ˆ: ì¡°í•­, ì•½ê´€, ì¡°ê±´, ì˜ë¬´ ë“±)"
    
    question_marks = ['?', '?']
    is_question = any(q in clause for q in question_marks)
    
    if is_question:
        return False, "ì§ˆë¬¸ í˜•ì‹ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì•½ê´€ ì¡°í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”"
    
    return True, "ê²€ì¦ í†µê³¼"

def clean_text_node(state: ContractState):
    print(f"\n[ë…¸ë“œ1] Rule-based ê²€ì¦ + í…ìŠ¤íŠ¸ ì •ì œ\n")
    
    is_valid, validation_msg = is_valid_contract_clause(state['clause'])
    print(f"[Rule-based ê²€ì¦ ê²°ê³¼] {validation_msg}")
    
    if not is_valid:
        print(f"-> API í˜¸ì¶œ ì¤‘ë‹¨\n")
        return {
            "cleaned_text": "[ë£° ë² ì´ìŠ¤ ê±°ë¶€] ì•½ê´€ ì¡°í•­ì´ ì•„ë‹˜",
            "validation_failed": True
        }
    
    print(f"-> ê²€ì¦ í†µê³¼\n")
    
    original_text = state['clause']
    cleaned = original_text
    
    cleaned = re.sub(r'^[\sâ€¢\-\*]+', '', cleaned, flags=re.MULTILINE)
    cleaned = re.sub(r'[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\s*', '', cleaned)
    cleaned = re.sub(r'\(\d+\)\s*', '', cleaned)
    cleaned = re.sub(r'\s+', ' ', cleaned)
    cleaned = cleaned.strip()
    
    print(f"[ì •ì œ ì „] {len(original_text)}ì")
    print(f"{original_text}\n")
    print(f"[ì •ì œ í›„] {len(cleaned)}ì")
    print(f"{cleaned}\n")
    
    return {
        "cleaned_text": cleaned,
        "validation_failed": False
    }

def classify_type_node(state: ContractState):
    print(f"[ë…¸ë“œ2] Solar API - ë¶ˆê³µì • ìœ í˜• ë¶„ë¥˜\n")
    
    prompt = ACTIVE_UNFAIR_TYPE_PROMPT.format(
        clause=state['cleaned_text']
    )
    
    unfair_type = llm.invoke(prompt).content.strip()
    
    print(f"ë¶„ë¥˜ ê²°ê³¼: {unfair_type}\n")
    
    return {"unfair_type": unfair_type}

def retrieve_node(state: ContractState, vectorstore):
    
    current_threshold = state.get('similarity_threshold', SIMILARITY_THRESHOLD)
    print(f"[ë…¸ë“œ3] ê²€ìƒ‰ (ì„ê³„ê°’: {current_threshold:.0%})")
    
    search_query = f"{state['unfair_type']} {state['cleaned_text']}"
    
    # 1. ì‚¬ë¡€ ê²€ìƒ‰ (ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨)
    # ì´ í•¨ìˆ˜ëŠ” (doc, similarity_score) íŠœí”Œì„ ë°˜í™˜í•©ë‹ˆë‹¤. (1.0ì´ 100% ìœ ì‚¬)
    results_cases_with_scores = vectorstore.similarity_search_with_relevance_scores(
        search_query, 
        k=SEARCH_TOP_K_CASES, 
        filter={"source_type": "case"}
    )
    
    filtered_cases_meta = []
    
    for i, (doc, similarity_score) in enumerate(results_cases_with_scores, 1):
        
        # similarity_score (ì˜ˆ: 0.75)ë¥¼ current_threshold (ì˜ˆ: 0.70)ì™€ ì§ì ‘ ë¹„êµ
        if similarity_score >= current_threshold:
            print(f"  âœ“ ì‚¬ë¡€ í†µê³¼ (ìœ ì‚¬ë„ {similarity_score:.1%})") # ë””ë²„ê¹…ìš© ë¡œê·¸
            filtered_cases_meta.append({
                "index": i,
                "similarity": similarity_score, # ê³„ì‚°ì´ ì•„ë‹Œ, ë°˜í™˜ëœ ì ìˆ˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                "content": doc.page_content,
                "date": doc.metadata.get('date', 'N/A'),
                "case_type": doc.metadata.get('case_type', ''),
                "explanation": doc.metadata.get('explanation', ''),
                "conclusion": doc.metadata.get('conclusion', ''),
                "related_law": doc.metadata.get('related_law', '')
            })
        else:
             print(f"  âœ— ì‚¬ë¡€ í•„í„°ë¨ (ìœ ì‚¬ë„ {similarity_score:.1%})") # ë””ë²„ê¹…ìš© ë¡œê·¸

    # í‘œì‹œ ê°œìˆ˜ ì œí•œ
    final_cases_meta = filtered_cases_meta[:MAX_DISPLAY_CASES]
    
    # 2. ë²•ë ¹ ê²€ìƒ‰
    law_query = " ".join([c['related_law'] for c in final_cases_meta if c['related_law']])
    if not law_query: law_query = search_query
        
    results_laws_with_scores = vectorstore.similarity_search_with_relevance_scores(
        law_query, 
        k=SEARCH_TOP_K_LAWS, 
        filter={"source_type": "law"}
    )
    
    final_laws_meta = []
    for i, (doc, similarity_score) in enumerate(results_laws_with_scores, 1):
        if similarity_score >= current_threshold:
            final_laws_meta.append({
                "index": i,
                "similarity": similarity_score,
                "content": doc.page_content,
                "metadata": doc.metadata
            })
    final_laws_meta = final_laws_meta[:MAX_DISPLAY_LAWS]

    # 3. LLM í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ ìƒì„±
    retrieved_text = f"[ìœ ì‚¬ ì‹œì • ì‚¬ë¡€] ({len(final_cases_meta)}ê±´, ì„ê³„ì : {current_threshold:.0%})\n"
    
    for c in final_cases_meta:
        retrieved_text += f"\n- ì‚¬ë¡€{c['index']} (ìœ ì‚¬ë„ {c['similarity']:.1%}): {c['content']}\n"
        if c['related_law']:
            retrieved_text += f"  (ê´€ë ¨ë²•: {c['related_law']})\n"
    
    retrieved_text += f"\n[ê´€ë ¨ ë²•ë ¹] ({len(final_laws_meta)}ê±´)\n"
    for l in final_laws_meta:
        retrieved_text += f"- ë²•ë ¹{l['index']} (ìœ ì‚¬ë„ {l['similarity']:.1%}): {l['content']}\n"

    return {
        "related_cases": retrieved_text,
        "retrieved_cases_metadata": final_cases_meta,
        "retrieved_laws_metadata": final_laws_meta
    }

def generate_proposal_node(state: ContractState):
    print(f"[ë…¸ë“œ4] Solar API - ê°œì„ ì•ˆ ìƒì„± (ë°˜ë³µ: {state['iteration']}/{MAX_ITERATIONS})\n")
    
    # íŒŒì¼ ì´ë¦„-ë²• ì´ë¦„ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ì¶”ê°€
    LAW_FILENAME_MAP = {
        "1_ì•½ê´€ë²•.pdf": "ì•½ê´€ë²•",
        "1-2_ì•½ê´€ì‹¬ì‚¬ì§€ì¹¨.pdf": "ì•½ê´€ì‹¬ì‚¬ì§€ì¹¨",
        "2_ê¸ˆìœµì†Œë¹„ìë²•ì‹œí–‰ë ¹.pdf": "ê¸ˆìœµì†Œë¹„ìë²• ì‹œí–‰ë ¹",
        "3_ê¸ˆìœµì†Œë¹„ìë³´í˜¸ì—ê´€í•œê°ë…ê·œì •.pdf": "ê¸ˆìœµì†Œë¹„ìë³´í˜¸ ê°ë…ê·œì •",
        "4_ì „ìê¸ˆìœµê±°ë˜ë²•.pdf": "ì „ìê¸ˆìœµê±°ë˜ë²•" 
        # (build_vectordb.pyì˜ pdf_files ëª©ë¡ê³¼ ì¼ì¹˜ì‹œì¼œì•¼ í•¨)
    }
    
    # ìƒíƒœì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    unfair_type = state['unfair_type']
    cases_meta = state.get('retrieved_cases_metadata', [])
    laws_meta = state.get('retrieved_laws_metadata', [])
    original_clause = state['cleaned_text']
    
    # ìµœì¢… ì¶œë ¥ ë¬¸ìì—´(final_output) ì¡°ë¦½ ì‹œì‘ ---
    
    # 0. ë¶ˆê³µì • ì—¬ë¶€ íŒë‹¨
    final_output = "### 0. ë¶ˆê³µì • ì—¬ë¶€ íŒë‹¨\n"
    if unfair_type == "ê³µì •":
        final_output += "âœ… **ê³µì •**\n"
    else:
        # classify_type_nodeê°€ 'ë¶ˆê³µì • (ìœ í˜•)'ì„ ë°˜í™˜í•˜ë¯€ë¡œ í•˜ì´í”ˆ ì œê±°
        final_output += f"âŒ **{unfair_type}**\n"
        
    # 1. ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ì‚¬ë¡€
    final_output += "\n### 1. ìœ ì‚¬í•œ ì‚¬ë¡€\n"
    if not cases_meta:
        final_output += "ê´€ë ¨ ì‚¬ë¡€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
    else:
        for case in cases_meta:
            case_summary = case['content'].split('ì•½ê´€:')[1].split('ê²°ë¡ :')[0].strip()
            if len(case_summary) > 70:
                case_summary = case_summary[:70] + "..."
            final_output += f"* **`(ìœ ì‚¬ë„ {case['similarity']:.0%})`** {case_summary}\n"
            
    # 2. ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë²•ë ¹
    final_output += "\n### 2. ì°¸ê³  ë²•ë ¹\n"
    if not laws_meta:
        final_output += "ê´€ë ¨ ë²•ë ¹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
    else:
        for law in laws_meta:
            similarity = law['similarity']
            content = law['content'].strip()
            metadata = law.get('metadata', {})
            
            # ë©”íƒ€ë°ì´í„°ì—ì„œ íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ë²• ì´ë¦„ ì°¾ê¸°
            source_file = metadata.get('source_file', 'ì•Œ ìˆ˜ ì—†ëŠ” ë²•ë ¹')
            law_name = LAW_FILENAME_MAP.get(source_file, source_file)
            
            # ë‚´ìš© ìš”ì•½ (70ì)
            if len(content) > 70:
                content = content[:70] + "..."
            
            # [ã…‡ã…‡ë²•] - [ì œã…‡ì¡°...] í˜•ì‹ìœ¼ë¡œ ì¡°í•©
            final_output += f"* **`(ìœ ì‚¬ë„ {similarity:.0%})`** **`[{law_name}]`** - {content}\n"

    # --- 2. "ê³µì •"í•  ê²½ìš°, ì—¬ê¸°ì„œ ì™„ë£Œ ---
    if unfair_type == "ê³µì •":
        print("ê³µì • ì¡°í•­ìœ¼ë¡œ íŒë‹¨ë˜ì–´ ê°œì„ ì•ˆ ìƒì„± ì—†ì´ ì™„ë£Œ.\n")
        return {"improvement_proposal": final_output}

    # --- 3. "ë¶ˆê³µì •"í•  ê²½ìš°, LLMì„ í˜¸ì¶œí•˜ì—¬ ê°œì„ ì•ˆ + í‘œ ìƒì„± ---
    
    print("ë¶ˆê³µì • ì¡°í•­ìœ¼ë¡œ íŒë‹¨ë˜ì–´ LLM ê°œì„ ì•ˆ ìƒì„± ì‹œì‘...\n")
    
    # ì‚¬ìš©ì í”¼ë“œë°± (ì¬ì‹œë„ ì‹œ)
    feedback_context = ""
    if state.get('modify_reason'):
        feedback_context = f"\n[ì¶”ê°€ ì‚¬ìš©ì í”¼ë“œë°±]\n{state['modify_reason']}\nìœ„ ì˜ê²¬ì„ ë°˜ì˜í•´ ë‹¤ì‹œ ì‘ì„±í•˜ì„¸ìš”.\n"

    # LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ (ì¸ë¼ì¸ diff ë° í…Œì´ë¸” ìƒì„± ìš”ì²­)
    prompt = ACTIVE_IMPROVEMENT_PROMPT.format(
        original_clause=original_clause,
        unfair_type=unfair_type,
        related_context=state['related_cases'], # prompts.pyì˜ {related_context}ì™€ ë§¤ì¹­
        feedback_context=feedback_context
    )
    
    # LLM í˜¸ì¶œ
    llm_response = llm.invoke(prompt).content
    
    # LLM ì‘ë‹µì„ ìµœì¢… ì¶œë ¥ì— ì¶”ê°€
    final_output += f"\n{llm_response}"
    
    print("LLM ê°œì„ ì•ˆ ìƒì„± ì™„ë£Œ.\n")
    
    return {"improvement_proposal": final_output}

def ui_feedback_node(state: ContractState):
    print(f"\n[ë…¸ë“œ5] UI í”¼ë“œë°± ëŒ€ê¸° (ë°˜ë³µ: {state['iteration']}/{MAX_ITERATIONS})\n")
    print(f"ê°œì„ ì•ˆ:\n{state['improvement_proposal']}\n")
    
    if state.get('retrieved_cases_metadata'):
        print(f"ì°¸ê³ í•œ ì‚¬ë¡€ ìˆ˜: {len(state['retrieved_cases_metadata'])}ê°œ")
        for case in state['retrieved_cases_metadata']:
            print(f"  - ì‚¬ë¡€ {case['index']}: ìœ ì‚¬ë„ {case['similarity']:.2%}")
    
    return interrupt(state)

def process_feedback_node(state: ContractState):
    feedback = state['user_feedback']
    retry_action = state.get('retry_action', '')
    current_iteration = state.get('iteration', 1)
    
    if feedback == "approved":
        save_result(
            state=state,
            status="approved",
            iteration=current_iteration,
            total_iterations=current_iteration
        )
        print("[ë…¸ë“œ6] ê²°ê³¼ ì €ì¥ ì™„ë£Œ (ìˆ˜ë½)")
        print(f"ì´ {current_iteration}íšŒ ë°˜ë³µ í›„ ì™„ë£Œ\n")
        return {
            "user_feedback": "approved",
            "retry_action": ""
        }
    
    elif feedback == "rejected":
        if retry_action == "retry":
            new_iteration = current_iteration + 1
            save_result(
                state=state,
                status="rejected_retry",
                iteration=current_iteration
            )
            print(f"[ë…¸ë“œ6] ê±°ì ˆ ê¸°ë¡ (ì¬ì‹œë„ ì˜ˆì •)")
            print(f"-> ë°˜ë³µ {new_iteration}ì°¨ ì§„í–‰\n")
            return {
                "user_feedback": "rejected",
                "iteration": new_iteration,
                "retry_action": "retry"
            }
        else:
            save_result(
                state=state,
                status="rejected_discard",
                iteration=current_iteration,
                total_iterations=current_iteration
            )
            print(f"[ë…¸ë“œ6] ê²°ê³¼ ì €ì¥ ì™„ë£Œ (ê±°ì ˆ ë° íê¸°)\n")
            return {
                "user_feedback": "rejected",
                "retry_action": "discard"
            }
    
    elif feedback == "modify":
        if current_iteration >= MAX_ITERATIONS:
            save_result(
                state=state,
                status="max_iteration_reached",
                iteration=current_iteration,
                total_iterations=current_iteration,
                modify_reason="ë°˜ë³µ íšŸìˆ˜ ì œí•œ ë„ë‹¬"
            )
            print(f"[ë…¸ë“œ6] ë°˜ë³µ íšŸìˆ˜ ì œí•œ ë„ë‹¬")
            print(f"ì´ {current_iteration}íšŒ ë°˜ë³µ (ìµœëŒ€ê°’)\n")
            return {
                "user_feedback": "approved", 
                "retry_action": ""
            }
        
        new_iteration = current_iteration + 1
        save_result(
            state=state,
            status="modify_request",
            iteration=current_iteration,
            modify_reason=state.get('modify_reason', '')
        )
        print(f"[ë…¸ë“œ6] ìˆ˜ì • ìš”ì²­ ì €ì¥")
        print(f"-> ë°˜ë³µ {new_iteration}ì°¨ ì§„í–‰\n")
        return {
            "user_feedback": "modify",
            "iteration": new_iteration,
            "modify_reason": state.get('modify_reason', ''),
            "retry_action": ""
        }
    
    return {
        "user_feedback": feedback,
        "retry_action": ""
    }

def route_feedback(state: ContractState) -> str:
    if state.get('validation_failed', False):
        print("\n[ë¼ìš°íŒ… ê·œì¹™ ì ìš©]")
        print(f"- ì¡°ê±´: validation_failed == True")
        print(f"- ì•¡ì…˜: ê·¸ë˜í”„ ì¦‰ì‹œ ì¢…ë£Œ")
        print(f"- ìƒíƒœ: ë£°ë² ì´ìŠ¤ ê²€ì¦ ì‹¤íŒ¨\n")
        return "end"
    
    feedback = state.get('user_feedback', '').lower()
    retry_action = state.get('retry_action', '')
    current_iteration = state.get('iteration', 1)
    
    print(f"\n[ë¼ìš°íŒ… ê·œì¹™ ì ìš© - ë°˜ë³µ íšŸìˆ˜: {current_iteration}/{MAX_ITERATIONS}]")
    
    if feedback == "approved":
        print(f"- ì¡°ê±´: user_feedback == 'approved'")
        print(f"- ì•¡ì…˜: ê·¸ë˜í”„ ì¢…ë£Œ (ê²°ê³¼ ì €ì¥)")
        print(f"- ìƒíƒœ: ì™„ë£Œ\n")
        return "end"
    
    elif feedback == "rejected" and retry_action == "retry":
        print(f"- ì¡°ê±´: user_feedback == 'rejected' AND retry_action == 'retry'")
        print(f"- ì•¡ì…˜: generate ë…¸ë“œë¡œ ì´ë™ (ë‹¤ë¥¸ ê°œì„ ì•ˆ ìƒì„±)")
        print(f"- ìƒíƒœ: ì¬ì‹œë„ (ìƒˆë¡œìš´ ê°œì„ ì•ˆ)\n")
        return "generate"
    
    elif feedback == "rejected" and retry_action == "discard":
        print(f"- ì¡°ê±´: user_feedback == 'rejected' AND retry_action == 'discard'")
        print(f"- ì•¡ì…˜: ê·¸ë˜í”„ ì¢…ë£Œ (íê¸°)")
        print(f"- ìƒíƒœ: ê±°ì ˆ ë° íê¸°\n")
        return "end"
    
    elif feedback == "modify" and current_iteration < MAX_ITERATIONS:
        next_iteration = current_iteration + 1
        print(f"- ì¡°ê±´: user_feedback == 'modify' AND iteration({current_iteration}) < MAX({MAX_ITERATIONS})")
        print(f"- ì•¡ì…˜: generate ë…¸ë“œë¡œ ì´ë™ (í”¼ë“œë°± ë°˜ì˜)")
        print(f"- ìƒíƒœ: ë°˜ë³µ {next_iteration}ì°¨ ì§„í–‰\n")
        return "generate"
    
    elif feedback == "modify" and current_iteration >= MAX_ITERATIONS:
        print(f"- ì¡°ê±´: user_feedback == 'modify' AND iteration({current_iteration}) >= MAX({MAX_ITERATIONS})")
        print(f"- ë°˜ë³µ íšŸìˆ˜ ì œí•œ ë„ë‹¬!")
        print(f"- ì•¡ì…˜: ê·¸ë˜í”„ ì¢…ë£Œ (ê°•ì œ)")
        print(f"- ìƒíƒœ: ë°˜ë³µ ì œí•œ ë„ë‹¬\n")
        return "end"
    
    else:
        print(f"- ê¸°íƒ€ ì¡°ê±´")
        print(f"- ì•¡ì…˜: ê·¸ë˜í”„ ì¢…ë£Œ\n")
        return "end"

def save_result(state: ContractState, status: str, iteration: int,
                modify_reason: str = "", total_iterations: int = None):
    result = {
        "timestamp": datetime.now().isoformat(),
        "session_id": state['session_id'],
        "status": status,
        "iteration": iteration,
        "total_iterations": total_iterations or iteration,
        "original_clause": state['clause'],
        "cleaned_text": state['cleaned_text'],
        "unfair_type": state['unfair_type'],
        "improvement_proposal": state['improvement_proposal'],
        "modify_reason": modify_reason
    }
    
    filename = f"{status}_data.jsonl"
    with open(filename, 'a', encoding='utf-8') as f:
        f.write(json.dumps(result, ensure_ascii=False) + '\n')

def extract_text_from_pdf(uploaded_file):
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        reader = pypdf.PdfReader(uploaded_file)
        pdf_text = ""
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                pdf_text += page_text + "\n\n"
        return pdf_text
    except Exception as e:
        st.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""

def split_text_into_clauses(full_text: str) -> List[str]:
    """ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ìˆëŠ” ì¡°í•­(Chunk) ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""
    # ë²•ë¥  ë¬¸ì„œì— ì í•©í•œ êµ¬ë¶„ì ì„¤ì •
    # ì˜ˆ: "ì œ 1 ì¡°", "1.", "ê°€.", "â‘ " ë“±
    # RecursiveCharacterTextSplitterëŠ” \n\nì„ ìš°ì„ ìœ¼ë¡œ ìë¦…ë‹ˆë‹¤.
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,  # ì¡°í•­ í•˜ë‚˜ì˜ ìµœëŒ€ ê¸¸ì´ (ì¡°ì ˆ í•„ìš”)
        chunk_overlap=100, # ì¡°í•­ê°„ ê²¹ì¹¨
        separators=[
            "\n\n", "\n", ". ", " "
        ],
        length_function=len,
    )
    
    chunks = text_splitter.split_text(full_text)
    
    # ë„ˆë¬´ ì§§ì€ ì²­í¬(ì˜ˆ: ëª©ì°¨, í˜ì´ì§€ ë²ˆí˜¸) í•„í„°ë§
    # ê¸°ì¡´ 'is_valid_contract_clause'ì˜ ìµœì†Œ ê¸¸ì´ ê²€ì‚¬(20ì) í™œìš©
    valid_chunks = [
        chunk for chunk in chunks 
        if is_valid_contract_clause(chunk)[0] # ê¸°ì¡´ ë£°ë² ì´ìŠ¤ ê²€ì¦ ì¬í™œìš©
    ]
    
    return valid_chunks

def run_batch_analysis(app, chunks, similarity_threshold, vectorstore):
    """
    ì—¬ëŸ¬ ê°œì˜ ì¡°í•­(chunks)ì„ ìˆœíšŒí•˜ë©° ì¼ê´„ ë¶„ì„í•©ë‹ˆë‹¤.
    (HITLì´ ì—†ëŠ” ë‹¨ìˆœí•œ ì‹¤í–‰)
    """
    try:
        pass
    except Exception as e:
        st.error(f"ë²¡í„° DB ì ‘ê·¼ ì‹¤íŒ¨ (ì¼ê´„ ì²˜ë¦¬): {e}")
        return

    st.info(f"ì´ {len(chunks)}ê°œ ì¡°í•­ì— ëŒ€í•œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. (ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    
    progress_bar = st.progress(0, text="ë¶„ì„ ì§„í–‰ ì¤‘...")
    results = [] # ìµœì¢… ê²°ê³¼ ì €ì¥

    for i, chunk in enumerate(chunks):
        
        try:
            # 1. ì´ˆê¸° ìƒíƒœ ì •ì˜ (í”¼ë“œë°± ë…¸ë“œê°€ ì—†ìœ¼ë¯€ë¡œ ë‹¨ìˆœí™”)
            current_state = ContractState(
                clause=chunk,
                cleaned_text=chunk, # ìŠ¤í”Œë¦¬í„°ê°€ ì´ë¯¸ ì •ì œí–ˆë‹¤ê³  ê°€ì •
                iteration=1,
                session_id=f"batch_{i}",
                similarity_threshold=similarity_threshold,
                validation_failed=False
            )

            # 2. ë…¸ë“œ ìˆœì°¨ ì‹¤í–‰ (LangGraph 'app' ëŒ€ì‹  ì§ì ‘ í˜¸ì¶œ)
            
            # (Clean ë…¸ë“œëŠ” split_text_into_clausesì—ì„œ ì²˜ë¦¬)
            
            # [ë…¸ë“œ2] ìœ í˜• ë¶„ë¥˜
            type_result = classify_type_node(current_state)
            current_state.update(type_result)
            
            # [ë…¸ë“œ3] ê²€ìƒ‰
            retrieve_result = retrieve_node(current_state, vectorstore)
            current_state.update(retrieve_result)
            
            # [ë…¸ë“œ4] ê°œì„ ì•ˆ ìƒì„±
            proposal_result = generate_proposal_node(current_state)
            current_state.update(proposal_result)
            
            # 3. ê²°ê³¼ ì €ì¥
            results.append({
                "original_clause": chunk,
                "unfair_type": current_state['unfair_type'],
                "improvement_proposal": current_state['improvement_proposal'],
                "related_cases_count": len(current_state['retrieved_cases_metadata'])
            })

        except Exception as e:
            st.error(f"'ì¡°í•­ {i+1}' ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            results.append({
                "original_clause": chunk,
                "unfair_type": "ì˜¤ë¥˜",
                "improvement_proposal": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}",
                "related_cases_count": 0
            })
        
        # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì—…ë°ì´íŠ¸
        progress_bar.progress((i + 1) / len(chunks), text=f"ë¶„ì„ ì§„í–‰ ì¤‘... ({i+1}/{len(chunks)})")

    progress_bar.empty()
    st.success("ëª¨ë“  ì¡°í•­ ë¶„ì„ ì™„ë£Œ!")
    
    # 4. ê²°ê³¼ ë¦¬í¬íŠ¸ í‘œì‹œ
    display_batch_results(results)

def display_batch_results(results: List[dict]):
    """
    ì¼ê´„ ë¶„ì„ ê²°ê³¼ë¥¼ Streamlit UIì— ë¦¬í¬íŠ¸ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
    """
    
    # '8. ê¸°íƒ€ ë¶ˆê³µì • ì•½ê´€' ëŒ€ì‹  'ê³µì •'ì„ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§
    problematic_clauses = [
        r for r in results 
        if r['unfair_type'] not in ["ê³µì •", "ì˜¤ë¥˜"]
    ]
    
    st.header(f"ê²€í†  ê²°ê³¼: ì´ {len(results)}ê°œ ì¡°í•­ ì¤‘ {len(problematic_clauses)}ê°œì˜ ë¶ˆê³µì • ì˜ì‹¬ ì¡°í•­ ë°œê²¬")
    
    for i, res in enumerate(problematic_clauses):
        with st.expander(f"ì˜ì‹¬ ì¡°í•­ {i+1}: ({res['unfair_type']}) - {res['original_clause'][:50]}..."):
            
            # st.markdown()ì„ ì‚¬ìš©í•˜ì—¬ Markdown ì„œì‹ì„ ê·¸ëŒ€ë¡œ ë Œë”ë§
            st.markdown(res['improvement_proposal'], unsafe_allow_html=True)
            
@st.cache_resource
def get_app_and_vectorstore():
    vectorstore = load_vectordb()
    
    graph = StateGraph(ContractState)
    
    graph.add_node("clean", clean_text_node)
    graph.add_node("classify", classify_type_node)
    graph.add_node("retrieve", lambda state: retrieve_node(state, vectorstore))
    graph.add_node("generate", generate_proposal_node)
    graph.add_node("feedback", ui_feedback_node)
    graph.add_node("process_feedback", process_feedback_node)
    
    graph.set_entry_point("clean")
    
    def route_after_clean(state: ContractState) -> str:
        if state.get('validation_failed', False):
            return "end"
        return "classify"
    
    graph.add_conditional_edges(
        "clean",
        route_after_clean,
        {
            "end": END,
            "classify": "classify"
        }
    )
    
    graph.add_edge("classify", "retrieve")
    graph.add_edge("retrieve", "generate")
    graph.add_edge("generate", "feedback")
    graph.add_edge("feedback", "process_feedback")
    
    graph.add_conditional_edges(
        "process_feedback",
        route_feedback,
        {
            "end": END,
            "generate": "generate"
        }
    )
    
    checkpointer = MemorySaver()
    app = graph.compile(checkpointer=checkpointer)
    
    return app, vectorstore

def main_chatbot_ui():
    st.set_page_config(page_title="ë²•ë¥  ì•½ê´€ ê²€í†  ì±—ë´‡", layout="wide")
    st.title("ë²•ë¥  ì•½ê´€ ê²€í†  ì±—ë´‡")
    
    with st.sidebar:
        st.header("ê²€ìƒ‰ ì„¤ì •")
        similarity_threshold_percent = st.slider(
            "ìœ ì‚¬ë„ ì„ê³„ê°’ (%)",
            min_value=0,
            max_value=100,
            value=int(SIMILARITY_THRESHOLD * 100), # config ê¸°ë³¸ê°’ ì‚¬ìš©
            step=5,
            format="%d%%"
        )
        current_threshold_value = similarity_threshold_percent / 100.0
        st.caption(f"í˜„ì¬ ì„¤ì •: {similarity_threshold_percent}% ì´ìƒ")
        st.divider()
        
    try:
        app, vectorstore = get_app_and_vectorstore()
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.error("Chroma DB íŒŒì¼('./chroma_db')ì´ ì˜¬ë°”ë¥´ê²Œ ìœ„ì¹˜í•´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return
        
    tab1, tab2 = st.tabs(["ğŸ’¬ ì±—ë´‡ (ë‹¨ì¼ ì¡°í•­ ê²€í† )", "ğŸ“„ PDF (ì „ì²´ ë¬¸ì„œ ê²€í† )"])
    
    with tab1:
        run_chatbot_mode(app, current_threshold_value)
    
    with tab2:
        run_pdf_batch_mode(app, vectorstore, current_threshold_value)

def run_chatbot_mode(app, current_threshold_value):
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "thread_id" not in st.session_state:
        st.session_state.thread_id = None
    if "hitl_pending" not in st.session_state:
        st.session_state.hitl_pending = False
    if "current_state" not in st.session_state:
        st.session_state.current_state = {}
    if "pending_feedback" not in st.session_state:
        st.session_state.pending_feedback = None

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if st.session_state.hitl_pending:
        current_iteration = st.session_state.current_state.get('iteration', 1)
        used_threshold = st.session_state.current_state.get('similarity_threshold', SIMILARITY_THRESHOLD)
        
        if SHOW_RETRIEVED_CASES:
            with st.expander("ì°¸ê³ í•œ ìœ ì‚¬ ì‚¬ë¡€ ë³´ê¸°", expanded=False):
                cases = st.session_state.current_state.get('retrieved_cases_metadata', [])
                
                if cases:
                    st.caption(f"ì´ {len(cases)}ê°œ ì‚¬ë¡€ (ìœ ì‚¬ë„ {used_threshold:.0%} ì´ìƒ)")
                    
                    for case in cases:
                        similarity = case['similarity']
                        
                        if similarity >= 0.7:
                            color = "ğŸŸ¢"
                        elif similarity >= 0.5:
                            color = "ğŸŸ¡"
                        else:
                            color = "ğŸŸ "
                        
                        st.markdown(f"### {color} ì‚¬ë¡€ {case['index']} - ìœ ì‚¬ë„: {similarity:.1%}")
                        st.caption(f"ğŸ“… {case['date']} | ìœ í˜•: {case['case_type']}")
                        
                        with st.container():
                            st.markdown("**ì•½ê´€ ì¡°í•­:**")
                            st.info(case['content'].split('ê²°ë¡ :')[0].replace('ì•½ê´€: ', '').strip())
                            
                            if case['explanation']:
                                st.markdown("**ì‹œì • ìš”ì²­ ì‚¬ìœ :**")
                                st.warning(case['explanation'])
                            
                            if case['conclusion']:
                                st.markdown("**ìµœì¢… ê²°ë¡ :**")
                                st.success(case['conclusion'])
                            
                            if case['related_law']:
                                st.caption(f"ğŸ”— ê´€ë ¨ë²•: {case['related_law']}")
                        
                        st.divider()
                else:
                    st.warning("ê²€ìƒ‰ëœ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        st.info(f"ê°œì„ ì•ˆ (ë°˜ë³µ {current_iteration}/{MAX_ITERATIONS})ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì£¼ì„¸ìš”.")

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ìˆ˜ì • ìš”ì²­ (Modify)")
            modify_reason = st.text_area("ìˆ˜ì • ìš”ì²­ ì‚¬ìœ :", key="modify_reason_input")
            
            if current_iteration >= MAX_ITERATIONS:
                st.warning(f"ë°˜ë³µ íšŸìˆ˜ ì œí•œ({MAX_ITERATIONS}íšŒ)ì— ë„ë‹¬í•˜ì—¬ ë” ì´ìƒ ìˆ˜ì • ìš”ì²­ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                if st.button("í˜„ì¬ ê°œì„ ì•ˆ ìˆ˜ë½ (Approve)", use_container_width=True, type="primary"):
                    st.session_state.pending_feedback = {
                        "user_feedback": "approved",
                        "modify_reason": "ë°˜ë³µ íšŸìˆ˜ ì œí•œ ë„ë‹¬",
                        "retry_action": ""
                    }
                    st.session_state.hitl_pending = False
                    st.session_state.messages.append({
                        "role": "user", 
                        "content": "[í”¼ë“œë°±] ë°˜ë³µ ì´ˆê³¼ë¡œ í˜„ì¬ ê°œì„ ì•ˆì„ ìˆ˜ë½í•©ë‹ˆë‹¤."
                    })
                    st.rerun()
            else:
                if st.button("ìˆ˜ì • ìš”ì²­ ì œì¶œ (Modify)", key="modify_btn", use_container_width=True):
                    if not modify_reason.strip():
                        st.error("ìˆ˜ì • ìš”ì²­ ì‚¬ìœ ë¥¼ ë°˜ë“œì‹œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
                    else:
                        st.session_state.pending_feedback = {
                            "user_feedback": "modify",
                            "modify_reason": modify_reason.strip(),
                            "retry_action": ""
                        }
                        st.session_state.hitl_pending = False
                        st.session_state.messages.append({
                            "role": "user", 
                            "content": f"[í”¼ë“œë°±] ìˆ˜ì • ìš”ì²­:\n{modify_reason.strip()}"
                        })
                        st.rerun()

        with col2:
            st.subheader("ìˆ˜ë½ ë˜ëŠ” ê±°ì ˆ (Approve / Reject)")
            if st.button("ê°œì„ ì•ˆ ìˆ˜ë½ (Approve)", key="approve_btn", use_container_width=True):
                st.session_state.pending_feedback = {
                    "user_feedback": "approved",
                    "modify_reason": "",
                    "retry_action": ""
                }
                st.session_state.hitl_pending = False
                st.session_state.messages.append({
                    "role": "user", 
                    "content": "[í”¼ë“œë°±] ê°œì„ ì•ˆì„ ìˆ˜ë½í•©ë‹ˆë‹¤ (ì™„ë£Œ)."
                })
                st.rerun()

            if st.button("ë‹¤ë¥¸ ê°œì„ ì•ˆ ìƒì„± (Reject + Retry)", key="retry_btn", use_container_width=True):
                st.session_state.pending_feedback = {
                    "user_feedback": "rejected",
                    "retry_action": "retry",
                    "modify_reason": ""
                }
                st.session_state.hitl_pending = False
                st.session_state.messages.append({
                    "role": "user", 
                    "content": "[í”¼ë“œë°±] ê±°ì ˆ (ë‹¤ë¥¸ ê°œì„ ì•ˆ ì¬ì‹œë„)."
                })
                st.rerun()

            if st.button("íê¸° (Reject + Discard)", key="discard_btn", use_container_width=True):
                st.session_state.pending_feedback = {
                    "user_feedback": "rejected",
                    "retry_action": "discard",
                    "modify_reason": ""
                }
                st.session_state.hitl_pending = False
                st.session_state.messages.append({
                    "role": "user", 
                    "content": "[í”¼ë“œë°±] ê±°ì ˆ (ê²€í†  íê¸°)."
                })
                st.rerun()
        
        st.chat_input("í”¼ë“œë°±ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.", disabled=True)

    else:
        if st.session_state.pending_feedback is not None:
            feedback_input = st.session_state.pending_feedback
            st.session_state.pending_feedback = None
            
            config = {"configurable": {"thread_id": st.session_state.thread_id}}
            
            with st.chat_message("assistant"):
                with st.spinner("í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ì²˜ë¦¬ ì¤‘..."):
                    try:
                        output = app.invoke(feedback_input, config=config)
                        st.session_state.current_state = output
                        
                        last_feedback = output.get('user_feedback', '')
                        last_retry = output.get('retry_action', '')

                        if last_feedback == "approved" or (last_feedback == "rejected" and last_retry == "discard"):
                            st.markdown("### ê²€í†  ì™„ë£Œ\nê²€í† ê°€ ìµœì¢… ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": "ê²€í† ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
                            })
                            st.rerun()
                        else:
                            st.markdown(f"### ğŸ”„ ìƒˆë¡œìš´ ê°œì„ ì•ˆ (ë°˜ë³µ {output.get('iteration', '?')}/{MAX_ITERATIONS})")
                            st.markdown(output['improvement_proposal'])
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": output['improvement_proposal']
                            })
                            st.session_state.hitl_pending = True
                            st.rerun()

                    except Exception as e:
                        st.error(f"í”¼ë“œë°± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        st.session_state.hitl_pending = False
                        st.session_state.thread_id = None
                        st.session_state.current_state = {}

        elif prompt := st.chat_input("ê²€í† í•  ì•½ê´€ ì¡°í•­ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                with st.spinner("ì•½ê´€ ì¡°í•­ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        st.session_state.thread_id = f"session_{datetime.now().timestamp()}"
                        config = {"configurable": {"thread_id": st.session_state.thread_id}}
                        
                        initial_state = {
                            "clause": prompt,
                            "iteration": 1,
                            "session_id": st.session_state.thread_id,
                            "validation_failed": False,
                            "retrieved_cases_metadata": [],
                            "retrieved_laws_metadata": [],
                            "similarity_threshold": current_threshold_value
                        }
                        
                        with tracing_v2_enabled():
                            output = app.invoke(initial_state, config=config)
                        
                        st.session_state.current_state = output
                        
                        if output.get('validation_failed', False):
                            error_msg = f"ì…ë ¥ ì˜¤ë¥˜: {output.get('cleaned_text', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                            st.error(error_msg)
                            st.session_state.messages.append({"role": "assistant", "content": error_msg})
                            st.session_state.thread_id = None
                        else:
                            st.markdown("### ì œì•ˆ (ì²« ë²ˆì§¸ ê°œì„ ì•ˆ)")
                            st.markdown(output['improvement_proposal'])
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": output['improvement_proposal']
                            })
                            st.session_state.hitl_pending = True
                            st.rerun()

                    except Exception as e:
                        st.error(f"ì•½ê´€ ê²€í†  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        import traceback
                        st.exception(traceback.format_exc())
                        st.session_state.thread_id = None
                        st.session_state.hitl_pending = False
                        st.session_state.current_state = {}

def run_pdf_batch_mode(app, vectorstore, current_threshold_value):
    st.header("PDF ì•½ê´€ ì „ì²´ ê²€í† ")
    st.info("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë¬¸ì„œ ì „ì²´ë¥¼ ë¶„ì„í•˜ì—¬ 'ë¶ˆê³µì • ì˜ì‹¬ ì¡°í•­' ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.")

    uploaded_file = st.file_uploader(
        "ğŸ“„ ê²€í† í•  PDF ì•½ê´€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", 
        type="pdf",
        key="pdf_uploader" # keyë¥¼ ì¶”ê°€í•˜ì—¬ íƒ­ ì „í™˜ ì‹œ íŒŒì¼ì´ ìœ ì§€ë˜ë„ë¡ í•¨
    )
    
    if uploaded_file is not None:
        # 1. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        pdf_text = extract_text_from_pdf(uploaded_file)
        
        # 2. í…ìŠ¤íŠ¸ ë¶„í•  (Chunking)
        chunks = split_text_into_clauses(pdf_text)
        
        st.markdown(f"ì´ {len(chunks)}ê°œì˜ ì¡°í•­(Chunk)ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        if st.button("ì „ì²´ ì¡°í•­ ë¶„ì„ ì‹œì‘í•˜ê¸°", type="primary", key="batch_start_btn"):
            # 3. vectorstoreë¥¼ run_batch_analysisë¡œ ì „ë‹¬
            run_batch_analysis(app, chunks, current_threshold_value, vectorstore)

if __name__ == "__main__":
    main_chatbot_ui()